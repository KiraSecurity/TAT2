#category: crawler
#input dependencies: full urls 
#language: go

import os
import subprocess

# Setup paths
cwd = os.getcwd()
go_bin_path = f'{cwd}/bins/go/bin'
nomore403_bin_path = f'{cwd}/modules/enumeration/nomore403/bin'  # Ensure this points to a directory for binaries

# Create the directory if it doesn't exist
os.makedirs(nomore403_bin_path, exist_ok=True)

# Set environment variables
os.environ['PATH'] = f'{go_bin_path}:{nomore403_bin_path}:' + os.environ['PATH']
os.environ['GOPATH'] = cwd
os.environ['GOBIN'] = nomore403_bin_path

# Install the module
install_command = f'{go_bin_path}/go install -v github.com/devploit/nomore403@latest'
os.system(install_command)
url= 'facebook.com'
command = f'{nomore403_bin_path}/nomore403 -u {url}'
result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)
print(result.stdout)
try:
    if os.path.exists('abs_urls.txt'):
        with open('abs_urls.txt', 'r') as file:
            urls = file.readlines()

        for url in urls:
            url = url.strip()
            #print(f"Processing URL: {url}")

            if "[403]" in url:
                print(f"Processing URL: {url}")
                url = url.replace("[403]", "")
                print(f"Sanitized URL: {url}")

                # Run the nomore403 command
                command = f'{nomore403_bin_path}/nomore403 -u {url}'
                result = subprocess.run(command, shell=True, capture_output=True, text=True, check=True)
                print(result.stdout)

                # Append the results to nomore403.txt
                with open('nomore403.txt', 'a') as output_file:
                    output_file.write(f"URL: {url}\n")
                    output_file.write(result.stdout)
                    output_file.write("\n")
except Exception as e:
    print("Failed to execute nomore403:")
    print(e)
